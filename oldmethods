void VisionService::identifyWagons(std::vector<cv::RotatedRect>& wagons, cv::Mat& grayImage)
{
    cv::Mat maskedWagon(this->height, this->width, CV_8UC1);
    cv::Mat mask = cv::Mat(this->height, this->width, CV_8UC1);
    mask.setTo(cv::Scalar(0));
    getRectWagonMask(wagons,mask);
    //getContourWagonMask(this->wagonSpecs, contours,mask);

    // Using a negative mask, set background white
    cv::Mat negativeMask = cv::Mat(this->height, this->width, CV_8UC1);
    negativeMask.setTo(cv::Scalar(255));
    cv::Mat tmp = cv::Mat(this->height, this->width, CV_8UC1);
    cv::bitwise_not(mask,negativeMask);
    cv::bitwise_or(grayImage,negativeMask,tmp);
    cv::threshold(tmp, maskedWagon, 70, 255, cv::THRESH_BINARY);


    std::string wagonLettersFound;
    for (auto& it : wagons)
    {
        cv::Rect r = it.boundingRect();
        cv::Mat label = maskedWagon(r);
        label = label.clone();
        cv::Mat rotatedLabel(100,100,CV_8UC1);
        cv::Point2f center(r.width/2,r.height/2);

        // if the width is larger than the height, it means that the rectangle is lying on its side.
        // So we'll add another 90 degrees to the angle
        float angle = it.angle;
        if (it.size.width > it.size.height) angle-=90;

        cv::Mat rotation = cv::getRotationMatrix2D(center, angle, 1);
        warpAffine(label, rotatedLabel, rotation, rotatedLabel.size(), cv::INTER_CUBIC,cv::BORDER_CONSTANT, cv::Scalar(255));

        std::string str;
        ocr->run(rotatedLabel,str);
        char letter = 0;
        for (char c : whitelist)
        {
            if (str.find(c) != std::string::npos)
            {
                letter = c;
                break;
            }
        }
        if (!letter)
        {
            cv::Mat rotation = cv::getRotationMatrix2D(center, angle+180, 1);
            warpAffine(label, rotatedLabel, rotation, rotatedLabel.size(), cv::INTER_CUBIC,cv::BORDER_CONSTANT, cv::Scalar(255));
            ocr->run(rotatedLabel,str);
            for (char c : whitelist)
            {
                if (str.find(c) != std::string::npos)
                {
                    letter = c;
                    break;
                }
            }
        }
        if (letter) wagonLettersFound += letter;
        //DEBUGIMG8(rotatedLabel);
    }

    qDebug() << wagonLettersFound.c_str();
}

// This is for getting the wagons mask using contour. It is slower than using getRectWagonMask but it's more precise
void VisionService::getContourWagonMask(DetectionSpecs specs, Contours& contours, cv::Mat& mask)
{
    Contours list;
    // Create mask using contours. This is more precise but sometimes
    // bleeds into the shape, flooding the letter
    for (auto& it : contours)
    {
        double epsilon = 0.1*cv::arcLength(it,true);
        std::vector<cv::Point> curve;
        cv::approxPolyDP(it,curve,epsilon,true);
        double area = cv::contourArea(curve);
        if (area < specs.areaSize) continue;
        list.push_back(it);
    }
    cv::drawContours(mask,list, -1, cv::Scalar(255),-1);
}

// This is for getting the wagons mask using rotated rect. It is faster than using getContourWagonMask but it's sloppier
void VisionService::getRectWagonMask(std::vector<cv::RotatedRect>& wagons, cv::Mat& mask)
{
    // Create mask using rotated rectangles
    for (cv::RotatedRect r : wagons)
    {
        cv::Point2f p2f[4];
        cv::Point p[4];
        r.points(p2f);
        for (int i=0; i<4; i++) p[i] = p[i] = p2f[i];
        cv::fillConvexPoly(mask,p,4,cv::Scalar(255));
    }
}

bool VisionService::detectDottedLabels(int w, int h, cv::Mat* grayImage)
{
    //////////////////////////////////
    // THIS IS NOT USED
    //////////////////////////////////
    Contours list;
    std::vector<cv::RotatedRect> locos;
    std::vector<cv::RotatedRect> wagons;
    Contours contours;
    std::vector<cv::Vec4i> hierarchy;
    cv::Mat* maskedCandidates = this->matrixPool.getMatrix("masked_candidates");
    cv::Mat* contoursMat = this->matrixPool.getMatrix("contours");
    contoursMat->create(h, w, CV_8UC1);
    cv::Mat tmp, tmp2, tmp3;

    cv::Mat* thresh = this->matrixPool.getMatrix("threshold");
    cv::threshold(*grayImage, *thresh, 60, 255, cv::THRESH_BINARY);

    //Get the adaptive threshold image
    cv::Mat* adaptive = this->matrixPool.getMatrix("adaptive");
    cv::adaptiveThreshold(*grayImage, *adaptive, 255, cv::ADAPTIVE_THRESH_MEAN_C, cv::THRESH_BINARY, 5,3);
    adaptive->copyTo(tmp, this->trackMask);


    cv::Mat* adaptiveeroded = this->matrixPool.getMatrix("adaptive_eroded");
    cv::erode(tmp, *adaptiveeroded, cv::Mat());

    cv::findContours(*adaptiveeroded, contours, hierarchy, cv::RETR_CCOMP, cv::CHAIN_APPROX_SIMPLE);
    cv::Mat mc(h,w,CV_8UC1);
    mc.setTo(255);
    for (int i =0; i < contours.size(); i++)
    {
        auto it = contours[i];
        cv::RotatedRect rr = cv::minAreaRect(it);
        cv::Rect r = cv::boundingRect(it);
        double area = rr.size.area();
        //float ratio = rr.size.width/rr.size.height;
        if (area < 200 || area >700) continue;
        if (r. width > 100 || r.height > 100) continue;
        if (r. width < 10 || r.height < 10) continue;
        //if (ratio > 4.0 || ratio < 0.25) continue;

        // The shape must have between 1 and 3 dots in it. So The contour must have between 1-3 children
        int childrenCount = 0;
        int childIndex = hierarchy[i][2];
        while (childIndex != -1)
        {
            auto it2 = contours[childIndex];
            //cv::Rect rc = cv::boundingRect(it2);
            cv::RotatedRect rr2 = cv::minAreaRect(it2);

            childIndex =  hierarchy[childIndex][0];

            if (rr2.size.area() < 10) continue;

            childrenCount++;
        }
        if (childrenCount > 5) continue;
        //if (childrenCount <1 || childrenCount > 3) continue;

        //if (childrenCount == 1 ) locos.push_back(rr);
        //else if (childrenCount == 2 ) wagons.push_back(rr);

        //qDebug() << childrenCount;


        cv::Mat source = (*grayImage)(r);
        source = source.clone();
        cv::Mat rotated(r.height,r.width,CV_8UC1);
        cv::Point2f center(r.width/2,r.height/2);
        float angle = rr.angle+90;
        if (rr.size.width > rr.size.height) angle-=90;

        cv::Mat rotation = cv::getRotationMatrix2D(center, angle, 1);
        warpAffine(source, rotated, rotation, rotated.size(), cv::INTER_CUBIC,cv::BORDER_CONSTANT, cv::Scalar(255));

        rotated.copyTo(mc.colRange(r.x,r.x+r.width).rowRange(r.y,r.y+r.height));
//        rotated.copyTo(maskedCandidates->rowRange(r.x,r.x+rr.size.width).colRange(r.y,r.y+rr.size.height));
        /*
        cv::Point2f p2f[4];
        cv::Point p[4];
        rr.points(p2f);
        for (int i=0; i<4; i++) p[i] = p[i] = p2f[i];
        cv::fillConvexPoly(*contoursMat, p, 4, cv::Scalar(255));*/

    }
    mc.copyTo(*maskedCandidates);
    //grayImage->copyTo(tmp2, *contoursMat);
    //cv::threshold(tmp2, *maskedCandidates, 100, 255, cv::THRESH_BINARY);

    qDebug() << "";
    //adaptive->copyTo(*maskedCandidates, *contoursMat);

    this->processDetectedWagons(wagons);
    bool locoDetected = false;
    if (!this->restrictLocomotiveDetectionToTracks)
    {
        locoDetected = this->processDetectedLocomotive(locos);
    }

    return locoDetected;
}











/*        std::vector<cv::Vec4i> lines;
        cv::HoughLinesP(rotated,lines,1, (CV_PI/180), 70, 0, 10);
qDebug() << lines.size();
        for(int i = 0; i < lines.size(); i++)
        {
            cv::Point pt1, pt2;
            //float rho = lines[i][0];
            //float theta = lines[i][1];
            //double a = cos(theta), b = sin(theta);
            //double x0 = a*rho, y0 = b*rho;
            //pt1.x = cvRound(x0 + 1000*(-b));
            //pt1.y = cvRound(y0 + 1000*(a));
            //pt2.x = cvRound(x0 - 1000*(-b));
            //pt2.y = cvRound(y0 - 1000*(a));

            pt1.x = lines[i][0];
            pt1.y = lines[i][1];
            pt2.x = lines[i][2];
            pt2.y = lines[i][3];
            cv::line(*cntmat, pt1, pt2, cv::Scalar(255), 3, cv::LINE_AA);
        }*/







        /*double a = CVNORM(lastDefect.x, lastDefect.y, ref.x, ref.y);
        double b = CVNORM(pfar.x, pfar.y, ref.x, ref.y);
        double c = CVNORM(lastDefect.x, lastDefect.y, pfar.x, pfar.y);
        double theta = acos(((a*a)+(b*b)-(c*c))/(2.0*a*b));
        if (theta < 1.3) // TODO: MAGIC NUMBER
        {
            color = cv::Scalar(0,0,255);
        }*/







    cv::Ptr<cv::BackgroundSubtractor> backgroundSubtractor;
    this->backgroundSubtractor.release();
    this->staticImage = cv::Mat(h,w,CV_8UC4);
    this->backgroundSubtractor = cv::createBackgroundSubtractorMOG2(10, 16, true);




    this->handMatrixPool->addName(MATRIX_DIFFERENCE_MASK, "difference_mask");
    this->handMatrixPool->addName(MATRIX_DIFFERENCE, "difference");
    this->handMatrixPool->addName(MATRIX_HANDCONTOUR, "hand_contour");
    FrameProcessingWorker* handWorker;
    void workOnHandDetection(std::shared_ptr<cv::Mat> original, std::shared_ptr<cv::Mat> hsv, std::shared_ptr<cv::Mat> gray, std::shared_ptr<cv::Mat> adaptive);
    this->handWorker = new FrameProcessingWorker([this](auto wi){ this->workOnHandDetection(wi.original, wi.hsv, wi.gray, wi.adaptive); });
void VisionService::workOnHandDetection(std::shared_ptr<cv::Mat> original, std::shared_ptr<cv::Mat> hsv, std::shared_ptr<cv::Mat> gray, std::shared_ptr<cv::Mat> adaptive)
{
    cv::Mat tmp;
    cv::Mat tmp2;
    Contours contours;
    QVector<QPoint> fingers;
    std::vector<cv::Vec4i> defects;
    std::vector<int> hull;
    std::vector<int> reducedHull;
    std::vector<std::pair<int, int>> candidates;
    Contour contour;
    cv::Point center;

    PerformanceMonitor::tic("VisionService::workOnHandDetection");
    this->handMatrixPool->startWorking();

    std::shared_ptr<cv::Mat> diffMask = this->handMatrixPool->getMatrix(MATRIX_DIFFERENCE_MASK);
    std::shared_ptr<cv::Mat> diff = this->handMatrixPool->getMatrix(MATRIX_DIFFERENCE);
    std::shared_ptr<cv::Mat> handContoursMat = this->handMatrixPool->getMatrix(MATRIX_HANDCONTOUR);
    handContoursMat->create(original->size(), CV_8UC4);
    handContoursMat->setTo(0);
    //backgroundSubtractor->apply(*original,*diff);

    //diff->create(VIDEO_HEIGHT, VIDEO_WIDTH, CV_8UC1);
    cv::absdiff(this->staticImage, *original, tmp2);
    cv::cvtColor(tmp2, tmp, cv::COLOR_BGR2GRAY);
    if (cv::mean(tmp)[0] > 60)
    {
        // TODO: find better way to update. Should instead do it when difference is very small ?
        // If the background changed drastically, update it
        original->copyTo(this->staticImage);
    }

    cv::threshold(tmp, *diffMask, 40, 255, 0);

    // find bigest shape using contours
    std::vector<cv::Vec4i> hierarchy;
    cv::findContours(*diffMask, contours, hierarchy, cv::RETR_CCOMP, cv::CHAIN_APPROX_NONE);
    for (int contourIndex = 0; contourIndex < contours.size(); contourIndex++)
    {
        contour = contours[contourIndex];

        double area = cv::contourArea(contour);
        if (area < 6000) continue;
        cv::RotatedRect rr = cv::minAreaRect(contour);

        center.x = rr.center.x;
        center.y = rr.center.y;
        cv::convexHull(contour, hull, true, true);
        if (hull.size() >= 3) break;

    }
    if (hull.size() <3) return;


    // Find all points that are close to each other in the hull
    std::vector<int> labels;
    int labelCount = cv::partition(hull, labels, [contour](int ia, int ib) {
        cv::Point a = contour[ia];
        cv::Point b = contour[ib];
        return (((a.x-b.x)*(a.x-b.x))+((a.y-b.y)*(a.y-b.y))) < 30; //TODO: MAGIC NUMBER
    });

    // Cluster those points together by keeping the first one we find.
    int currentLabel = 0;
    while (labelCount)
    {
        for (int i = 0; i < labels.size(); i++)
        {
            if (labels[i] == currentLabel)
            {
                reducedHull.push_back(hull.at(i));
                break;
            }
        }
        labelCount--;
        currentLabel++;
    }
    cv::convexityDefects(contour, reducedHull, defects);

    if (!defects.size()) return;

    if (this->handMatrixPool->getDebugEnabled())
    {
        Contours cc;
        cc.push_back(contour);
        cv::drawContours(*handContoursMat, cc, 0, cv::Scalar(255,255,255));
    }

    cv::Point lastDefect;
    lastDefect.x = -1;
    for (auto d : defects)
    {
        cv::Point pstart = contour[d[0]];
        cv::Point pend = contour[d[1]];
        cv::Point pfar = contour[d[2]];
        int depth = d[3];
        if (depth < 6000) continue;

        // the depth between the concave point and the hull should be large enough
        if (this->handMatrixPool->getDebugEnabled()) cv::circle(*handContoursMat, pfar, 5, cv::Scalar(255,0,0));

        auto color = cv::Scalar(0,255,255);

        if (lastDefect.x == -1) candidates.push_back({d[0], d[2]});
        candidates.push_back({d[1], d[2]});
        lastDefect = pfar;
    }

    for (int i = 0; i < candidates.size(); i++)
    {
        cv::Point cvp = contour[candidates[i].first];
        QPoint p = QPoint(cvp.x, cvp.y);

        int i1 = candidates[i].first+20;
        int i2 = candidates[i].first-20;
        if (i1> contour.size()) i1 -=contour.size();
        if (i2 < 0) i2 += contour.size();

        cv::Point p1 = contour[i1];
        cv::Point p2 = contour[i2];

        double fingerWidth = CVNORM(p1.x, p1.y, p2.x, p2.y);
        if (fingerWidth < 50)
        {
            if (this->handMatrixPool->getDebugEnabled()) cv::circle(*handContoursMat, cvp, 5, cv::Scalar(0,0,255));
            fingers.append(p);
        }

        cv::Point cvpf = contour[candidates[i].second];
        if (this->handMatrixPool->getDebugEnabled())
        {
            cv::line(*handContoursMat, center, cvpf, cv::Scalar(0,255,0), 1);
            cv::line(*handContoursMat, cvpf, cvp, cv::Scalar(0,255,255), 1);
            cv::line(*handContoursMat, p1, p2, cv::Scalar(0,0, 255), 1);
        }
    }

    if (fingers.size()) emit fingersDetected(fingers);






    this->handMatrixPool->stopWorking();
    //this->detectHand(hsv);
    PerformanceMonitor::toc("VisionService::workOnHandDetection");
}








